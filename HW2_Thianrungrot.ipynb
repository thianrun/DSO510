{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>rank</th>\n",
       "      <th>app_store</th>\n",
       "      <th>region</th>\n",
       "      <th>app_age_current_version</th>\n",
       "      <th>app_type</th>\n",
       "      <th>price</th>\n",
       "      <th>filesize</th>\n",
       "      <th>num_screenshot</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>category</th>\n",
       "      <th>in_app_ads</th>\n",
       "      <th>in_app_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smart_phone</td>\n",
       "      <td>260</td>\n",
       "      <td>Apple</td>\n",
       "      <td>CN</td>\n",
       "      <td>11</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>15.3</td>\n",
       "      <td>5</td>\n",
       "      <td>302</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Social</td>\n",
       "      <td>NO_IN_APP_ADS</td>\n",
       "      <td>NO_IN_APP_PURCHASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart_phone</td>\n",
       "      <td>368</td>\n",
       "      <td>Apple</td>\n",
       "      <td>CN</td>\n",
       "      <td>14</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10</td>\n",
       "      <td>2455</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Social</td>\n",
       "      <td>NO_IN_APP_ADS</td>\n",
       "      <td>NO_IN_APP_PURCHASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smart_phone</td>\n",
       "      <td>355</td>\n",
       "      <td>Apple</td>\n",
       "      <td>CN</td>\n",
       "      <td>51</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>25.4</td>\n",
       "      <td>10</td>\n",
       "      <td>117</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Social</td>\n",
       "      <td>NO_IN_APP_ADS</td>\n",
       "      <td>NO_IN_APP_PURCHASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smart_phone</td>\n",
       "      <td>165</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>US</td>\n",
       "      <td>21</td>\n",
       "      <td>paid</td>\n",
       "      <td>3.8042</td>\n",
       "      <td>294.0</td>\n",
       "      <td>5</td>\n",
       "      <td>647</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Games</td>\n",
       "      <td>NO_IN_APP_ADS</td>\n",
       "      <td>NO_IN_APP_PURCHASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smart_phone</td>\n",
       "      <td>211</td>\n",
       "      <td>Google Play</td>\n",
       "      <td>CN</td>\n",
       "      <td>39</td>\n",
       "      <td>free</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5</td>\n",
       "      <td>567</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Social</td>\n",
       "      <td>IN_APP_ADS</td>\n",
       "      <td>NO_IN_APP_PURCHASE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        device  rank    app_store region  app_age_current_version app_type  \\\n",
       "0  smart_phone   260        Apple     CN                       11     free   \n",
       "1  smart_phone   368        Apple     CN                       14     free   \n",
       "2  smart_phone   355        Apple     CN                       51     free   \n",
       "3  smart_phone   165  Google Play     US                       21     paid   \n",
       "4  smart_phone   211  Google Play     CN                       39     free   \n",
       "\n",
       "    price  filesize  num_screenshot  rating_count  average_rating category  \\\n",
       "0  0.0000      15.3               5           302             4.5   Social   \n",
       "1  0.0000       8.7              10          2455             5.0   Social   \n",
       "2  0.0000      25.4              10           117             3.0   Social   \n",
       "3  3.8042     294.0               5           647             4.5    Games   \n",
       "4  0.0000       6.8               5           567             3.3   Social   \n",
       "\n",
       "      in_app_ads     in_app_purchase  \n",
       "0  NO_IN_APP_ADS  NO_IN_APP_PURCHASE  \n",
       "1  NO_IN_APP_ADS  NO_IN_APP_PURCHASE  \n",
       "2  NO_IN_APP_ADS  NO_IN_APP_PURCHASE  \n",
       "3  NO_IN_APP_ADS  NO_IN_APP_PURCHASE  \n",
       "4     IN_APP_ADS  NO_IN_APP_PURCHASE  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('hw2_1.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18624 entries, 0 to 18623\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   device                   18624 non-null  object \n",
      " 1   rank                     18624 non-null  int64  \n",
      " 2   app_store                18624 non-null  object \n",
      " 3   region                   18624 non-null  object \n",
      " 4   app_age_current_version  18624 non-null  int64  \n",
      " 5   app_type                 18624 non-null  object \n",
      " 6   price                    18624 non-null  float64\n",
      " 7   filesize                 18624 non-null  float64\n",
      " 8   num_screenshot           18624 non-null  int64  \n",
      " 9   rating_count             18624 non-null  int64  \n",
      " 10  average_rating           18624 non-null  float64\n",
      " 11  category                 18624 non-null  object \n",
      " 12  in_app_ads               18624 non-null  object \n",
      " 13  in_app_purchase          18624 non-null  object \n",
      "dtypes: float64(3), int64(4), object(7)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18624"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "<f>Using the data, estimate a linear model for the relationship between demand and price. For this you have access to a large volume of app level data (in a file called **hw2_1.csv**), including information about the ‘rank’ of the app on the app store. Assume Sales = (1/rank)*1,000,000 (don’t worry about the details behind this assumption, just make the assumption). Specifically, estimate a univariate regression where the dependent variable is sales and the independent variable is price:\n",
    "$Sales = \\beta_0 +\\beta_1 * Price$</f>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Report the estimated intercept and the estimated slope coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "$Sales = 20,703.82797 - 469.785008*Price$\n",
    "\n",
    "intercept is 20703.827970<br>\n",
    "slope is  -469.785008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sales'] = (1/data['rank'])*1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    20703.827970\n",
       "price         -469.785008\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1a = sm.ols('Sales ~ price', data = data).fit()\n",
    "\n",
    "result_1a.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Test the following null hypothesis: $\\beta_1 = 0$. Use a 5% significance level.\n",
    "Provide an explanation of your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "As seen in the result below, P-value of price variable is 0.000 which lower than alpha 0.05. Hence, I can reject Null Hypothesis at 5% significance level and conclude that price variable impcat sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     13.06\n",
      "Date:                Sun, 21 Nov 2021   Prob (F-statistic):           0.000302\n",
      "Time:                        15:13:41   Log-Likelihood:            -2.3509e+05\n",
      "No. Observations:               18624   AIC:                         4.702e+05\n",
      "Df Residuals:                   18622   BIC:                         4.702e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    2.07e+04    586.506     35.300      0.000    1.96e+04    2.19e+04\n",
      "price       -469.7850    129.982     -3.614      0.000    -724.562    -215.008\n",
      "==============================================================================\n",
      "Omnibus:                    29159.253   Durbin-Watson:                   1.990\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         12140072.734\n",
      "Skew:                          10.270   Prob(JB):                         0.00\n",
      "Kurtosis:                     126.380   Cond. No.                         4.96\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(result_1a.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "<f> Create a dummy/binary variable for region. This variable should have a value of 0 if the region is CN (China) and 1 if the region is US (USA). Estimate a univariate regression of sales on this newly created variable. Provide a screenshot and an interpretation of both estimated coefficients. Be specific</f>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Interception is 17,630 which means that the average sales of applications in China store is $17,630.\n",
    "\n",
    "Coefficicient of region is 5,114.4716 with p-value 0.000. This means that region effect the sales. When the applications appear in the US store, the sales will increase $5,114.4716. In other words, the average sales of applications in US store is $17,630 + $5,114.4716 = $22,744.4716."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dummy_reg'] = [1 if i == 'US' else 0 for i in data['region']]\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     22.22\n",
      "Date:                Sun, 21 Nov 2021   Prob (F-statistic):           2.45e-06\n",
      "Time:                        15:13:41   Log-Likelihood:            -2.3509e+05\n",
      "No. Observations:               18624   AIC:                         4.702e+05\n",
      "Df Residuals:                   18622   BIC:                         4.702e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   1.763e+04    716.421     24.610      0.000    1.62e+04     1.9e+04\n",
      "dummy_reg   5114.4716   1084.992      4.714      0.000    2987.788    7241.155\n",
      "==============================================================================\n",
      "Omnibus:                    29156.082   Durbin-Watson:                   1.989\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         12133922.922\n",
      "Skew:                          10.267   Prob(JB):                         0.00\n",
      "Kurtosis:                     126.348   Cond. No.                         2.50\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "result2 = sm.ols('Sales ~ dummy_reg', data = data).fit()\n",
    "\n",
    "print(result2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Create another dummy/binary variable for in app advertisements (in_app_ads). This variable should have a value of 1 if the device has in app advertising and a value of 0 if the device does NOT have in app advertising. Estimate a regression of sales on the dummy variable created in part 2 and this newly created dummy variable (all in the same model). Provide a screenshot of the results and provide an interpretation of all the coefficients. Be Specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Interception is 16,540. This means that the average sales of applications that are in China store and do not have in-app advertisement is $16,540.\n",
    "\n",
    "Coefficient of region is 4964.4506. This means that the average sales of applications in US store is $4964.4506 more than those in China store.\n",
    "\n",
    "Coefficient of in-app advertisement is 3910.1267. This means that applications that have in-app advertisements have average sales $3,910.1267 more than those that do not have in-app advertisement.\n",
    "\n",
    "The average sales:\n",
    "| Region/In-app advertisement | Have in-app advertisement | Do not have in-app advertisement |\n",
    "| --- | --- | --- |\n",
    "| US | $25,414.5773 | $21,504.4506 |\n",
    "| China | $20,450.1267 | $16,540 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dummy_in_app_ads'] = [1 if i == 'IN_APP_ADS' else 0 for i in data['in_app_ads']]\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     16.61\n",
      "Date:                Sun, 21 Nov 2021   Prob (F-statistic):           6.23e-08\n",
      "Time:                        15:13:41   Log-Likelihood:            -2.3508e+05\n",
      "No. Observations:               18624   AIC:                         4.702e+05\n",
      "Df Residuals:                   18621   BIC:                         4.702e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept         1.654e+04    788.140     20.988      0.000     1.5e+04    1.81e+04\n",
      "dummy_reg         4964.4506   1085.646      4.573      0.000    2836.486    7092.415\n",
      "dummy_in_app_ads  3910.1267   1179.941      3.314      0.001    1597.335    6222.919\n",
      "==============================================================================\n",
      "Omnibus:                    29151.725   Durbin-Watson:                   1.991\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         12122923.670\n",
      "Skew:                          10.264   Prob(JB):                         0.00\n",
      "Kurtosis:                     126.292   Cond. No.                         2.75\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "result3 = sm.ols('Sales ~ dummy_reg + dummy_in_app_ads', data = data).fit()\n",
    "\n",
    "print(result3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Estimate a univariate regression of sales on price (similar to part 1) except in this case your model should able to speak in terms of elasticity. By elasticity you want to speak to your management in percentage terms – what is the % change in sales for a % increase in price? (Tip: we do this using log-log-regression models.) Since price can have a value of 0, you will have to adjust the variable. You can do this by adding 1 to each price and then taking the log. Provide a screenshot of the results and provide an **interpretation** for all the coefficients. Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "From the coefficient of price we can imply that when price increases by 1%, sales will decrease 0.0617%.\n",
    "\n",
    "From the interception, when price is equal to 0, expected sales is exp(8.9709)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1c/xy5l3bvx653590381s90cwv80000gn/T/ipykernel_53584/1500619858.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_q4['adjusted_price'] = data_q4['price'] + 1\n",
      "/var/folders/1c/xy5l3bvx653590381s90cwv80000gn/T/ipykernel_53584/1500619858.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_q4['log_sales'] = np.log(data['Sales'])\n",
      "/var/folders/1c/xy5l3bvx653590381s90cwv80000gn/T/ipykernel_53584/1500619858.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_q4['log_price'] = np.log(data_q4['adjusted_price'])\n"
     ]
    }
   ],
   "source": [
    "data_q4 = data[['Sales','price']]\n",
    "data_q4['adjusted_price'] = data_q4['price'] + 1\n",
    "data_q4['log_sales'] = np.log(data['Sales'])\n",
    "data_q4['log_price'] = np.log(data_q4['adjusted_price'])\n",
    "\n",
    "# data_q4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              log_sales   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     38.35\n",
      "Date:                Sun, 21 Nov 2021   Prob (F-statistic):           6.03e-10\n",
      "Time:                        15:13:41   Log-Likelihood:                -26834.\n",
      "No. Observations:               18624   AIC:                         5.367e+04\n",
      "Df Residuals:                   18622   BIC:                         5.369e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      8.9709      0.010    899.535      0.000       8.951       8.990\n",
      "log_price     -0.0617      0.010     -6.193      0.000      -0.081      -0.042\n",
      "==============================================================================\n",
      "Omnibus:                     5798.827   Durbin-Watson:                   1.869\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            16943.643\n",
      "Skew:                           1.643   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.322   Cond. No.                         2.21\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "result4 = sm.ols('log_sales ~ log_price', data = data_q4).fit()\n",
    "\n",
    "print(result4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "The app retailer believes that other factors, specifically the filesize, the number of screenshots, and the average rating may also be associated with both sales and price. The retailers want a model that estimates the relationship between price and sales (similar to 4) except they want the impact of the above-mentioned factors to be controlled for. Estimate a model that accomplishes this. Your model should speak in terms of elasticity (same as part 4). Provide screenshots of your results and discuss how this model achieves what the retailers want. Provide an interpretation of all the estimated coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Assumed we controlled all variable except price and sales. Thus, filesize, number of screenshots, and average rating remain constant when price change.\n",
    "\n",
    "Coefficient of log(price) is -0.0678 and p-value is 0.000. We can imply that if price increase 1% and other variables remains at the same point, sales will decrease by 0.0678%.\n",
    "\n",
    "Interpretaion for interception and other variables:\n",
    "\n",
    "Interception: if all variables are equal to 0. The expected sales is exp(8.7695).\n",
    "\n",
    "Coefficient of filesize is 0.00008758 with which means that if the filesize increases by 1 unit, the sales will increase 0.008758%. For the p-value this is not statistically significant at alpha 0.01 but this is statistically significant at alpha 0.05.\n",
    "\n",
    "Coefficient of number of screenshots is -0.0009 which means that if the number of screenshots increases by 1 unit, the sales will decrease 0.09%. However, the p-value is more than 0.05, so this is not statistically significant.\n",
    "\n",
    "Coefficient of average rating is 0.0487 and p-value is 0.000. We can imply that if there is 1 unit increase in average rating and other variables remains at the same point, sales will increase 4.87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_q5 = pd.concat([data_q4,data[['filesize','num_screenshot','average_rating']]], axis = 1)\n",
    "\n",
    "# data_q5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              log_sales   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     20.54\n",
      "Date:                Sun, 21 Nov 2021   Prob (F-statistic):           6.59e-17\n",
      "Time:                        15:13:41   Log-Likelihood:                -26812.\n",
      "No. Observations:               18624   AIC:                         5.363e+04\n",
      "Df Residuals:                   18619   BIC:                         5.367e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          8.7695      0.040    219.143      0.000       8.691       8.848\n",
      "log_price         -0.0678      0.011     -6.211      0.000      -0.089      -0.046\n",
      "filesize        8.758e-05   3.49e-05      2.512      0.012    1.92e-05       0.000\n",
      "num_screenshot    -0.0009      0.003     -0.309      0.757      -0.007       0.005\n",
      "average_rating     0.0487      0.008      5.920      0.000       0.033       0.065\n",
      "==============================================================================\n",
      "Omnibus:                     5817.011   Durbin-Watson:                   1.872\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            17064.442\n",
      "Skew:                           1.646   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.339   Cond. No.                     1.43e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.43e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "result5 = sm.ols('log_sales ~ log_price+filesize+num_screenshot+average_rating',data = data_q5).fit()\n",
    "\n",
    "print(result5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "The retailer is also interested in understanding the impact of the in-app purchase option. Specifically, the retailer believes that the relationship between price and sales is different for apps with an in-app purchase option and apps without an in-app purchase option. To do this, estimate the same model that you estimated in part 5 except add an interaction term between price and in app purchase option (dummy variable). Provide the results and an interpretation of all the estimated coefficients. Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Interception: if all variables are equal to 0. The expected sales is exp(8.7850).\n",
    "\n",
    "Coefficient of log(price) is -0.0883 and p-value is 0.000. We can imply that if price increase 1% and other variables remains at the same point, sales will decrease by 0.0883%.\n",
    "\n",
    "Coefficient of interaction between price and in-app purchase is 0.0747 and p-value is 0.000. We can conclude that if applications have an in-app purchase option and price increase by 1%, sales will increase 0.0163%.\n",
    "\n",
    "Coefficient of filesize is 0.0002812 which means that if the filesize increases by 1 unit, the sales will increase 0.02812%. However, the p-value is more than 0.05, so this is not statistically significant.\n",
    "\n",
    "Coefficient of number of screenshots is -0.0009 which means that if the number of screenshots increases by 1 unit, the sales will decrease 0.09%. However, the p-value is more than 0.05, so this is not statistically significant.\n",
    "\n",
    "Coefficient of average rating is 0.0447 and p-value is 0.000. We can imply that if there is 1 unit increase in average rating and other variables remains at the same point, sales will increase 4.47%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_q6 = pd.concat([data_q5,data['in_app_purchase']],axis = 1)\n",
    "data_q6['have_in_app_purchase'] = [1 if i == 'PLUGIN_PURCHASE' else 0 for i in data_q6['in_app_purchase']]\n",
    "data_q6['pricepurchase'] = data_q6['price']*data_q6['have_in_app_purchase']\n",
    "data_q6['log_pricepurchase'] = np.log(data_q6['pricepurchase']+1)\n",
    "\n",
    "# data_q6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              log_sales   R-squared:                       0.005\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     20.53\n",
      "Date:                Sun, 21 Nov 2021   Prob (F-statistic):           1.66e-20\n",
      "Time:                        15:13:41   Log-Likelihood:                -26801.\n",
      "No. Observations:               18624   AIC:                         5.361e+04\n",
      "Df Residuals:                   18618   BIC:                         5.366e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept             8.7850      0.040    218.844      0.000       8.706       8.864\n",
      "log_price            -0.0883      0.012     -7.472      0.000      -0.111      -0.065\n",
      "filesize           2.812e-05   3.73e-05      0.755      0.450   -4.49e-05       0.000\n",
      "num_screenshot       -0.0009      0.003     -0.304      0.761      -0.007       0.005\n",
      "average_rating        0.0447      0.008      5.402      0.000       0.028       0.061\n",
      "log_pricepurchase     0.0747      0.017      4.517      0.000       0.042       0.107\n",
      "==============================================================================\n",
      "Omnibus:                     5811.840   Durbin-Watson:                   1.871\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            17056.080\n",
      "Skew:                           1.645   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.341   Cond. No.                     1.43e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.43e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "result6 = sm.ols('log_sales ~ log_price+filesize+num_screenshot+average_rating+log_pricepurchase',data = data_q6).fit()\n",
    "\n",
    "print(result6.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1\n",
    "You are interested in examining whether visitors to your website spend, on average, more than 12 minutes browsing the website. While you had not previously kept track of website visitors, you start tracking after deciding that you want this information. In the file **exercise_1.csv**, you will find the minutes spent browsing for a sample of 24 website visitors. Use this data to statistically evaluate whether, on average, website visitors spend more than 12 minutes browsing on your website. Be specific about your approach (set your alpha-level at 0.05). State the null/alternative hypothesis and your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "I will use t-test for this exercise because the sample is less than 24\n",
    "\n",
    "*Hypothesis:*<br>\n",
    "$H_0$: Website visitors spend less than or eqaul to 12 minutes on the website.<br>\n",
    "$H_1$: Website visitors spend more than 12 minutes on the website.\n",
    "\n",
    "From the result below,\n",
    "P-value is 0.046 which less than 0.05. Thus, we can reject $H_0$ and conclude that the visitors spend more than 12 minutes on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ex1 = pd.read_csv('exercise_1.csv',header = None)\n",
    "data_ex1.columns = ['time']\n",
    "\n",
    "# data_ex1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045989713634792644\n"
     ]
    }
   ],
   "source": [
    "result_21 = ttest_1samp(data_ex1, 12, alternative = 'greater')\n",
    "\n",
    "print(result_21.pvalue[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import chi2_contingency\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ex2 = pd.read_csv('exercise_2.csv')\n",
    "\n",
    "# data_ex2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Evaluate whether the new website design visits are statistically more likely to end in a sale than the visits to the original website design. You do not need to include other variables in your model since the customers were randomly assigned. Be specific about your approach (set your alpha-level at 0.05). State the null/alternative hypothesis and your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "In this case I will use proportion test to see whether the new website design result in greater proportion of customer who made purchase.\n",
    "\n",
    "*Hypothesis:*<br>\n",
    "$H_0$: Proportion of purchased visitors who landed on the new website is less than or equal to those of the old website.<br>\n",
    "$H_1$: Proportion of purchased visitors who landed on the new website is greater than or equal to those of the old website.\n",
    "\n",
    "After running the z-test, p-value is 0.00013. Hence, we can reject $H_0$ and conclude that visitors in the new website more likely made purchase during the visit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013372021544684026"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zstat, p_value = proportions_ztest(count= np.array([data_ex2[data_ex2['website_design'] == 0]['sale_1_0'].sum(),data_ex2[data_ex2['website_design'] == 1]['sale_1_0'].sum()])\n",
    "                                   ,nobs=np.array([data_ex2[data_ex2['website_design'] == 0]['sale_1_0'].count(),data_ex2[data_ex2['website_design'] == 1]['sale_1_0'].count()])\n",
    "                                   ,alternative = 'smaller')\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Examine whether there is a statistical difference between the mean of minutes_spent for the subset of consumers that were sent to the new website design and the subset that were sent to the original website design. You do not need to include other variables in your model since the customers were randomly assigned. Be specific about your approach (set you alpha-level at 0.05). State the null/alternative hypothesis and your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Before performing the test, I cleaned data by excluding the records that have minutes_spent less than zero. Then, I used two-sided t-test to test whether time spent of visitors in new website differs from that of visitors in old website.\n",
    "\n",
    "*Hypothesis*<br>\n",
    "$H_0$: Average time spent of visitors in new website equal to that of old website.<br>\n",
    "$H_1$: Average time spent of visitors in new website differ from that of old website.\n",
    "\n",
    "After perform the test, p-value is nearly 0.000. Thus, I can reject $H_0$ and conclude that the average time spent of visitors of new website differ from that of old website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATBElEQVR4nO3df/Bld13f8ecrWUP43WTcZNZlt+FHqlBHwa6IG8YBQzT+GBI7SYMVXTrUpFOiBCxtVEb6R53JDNTijw7NGmy2NGJCDCaijcY1ihJIWQISwuLEIiRrttkNTgttp8Cy7/5xzzZfNvvj3s33fN/3e+/zMXPn3nPuOfe+z969r+/5fr6fz+ekqpAkrb3TuguQpGVlAEtSEwNYkpoYwJLUxACWpCYbuguYxsUXX1x33nlndxmSNK1Ms9G6OAN+7LHHukuQpFW3LgJYkhaRASxJTQxgSWpiAEtSEwNYkpoYwJLUxACWpCYGsCQ1MYAlqYkBLElNDGBJamIAS1ITA1iSmhjA0pzZvGUrSaa+bd6ytbtknaJ1MR+wtEwe2fcwV1x/z9Tb33zV9hGr0Zg8A5akJgawJDUxgCWpiQEsSU0MYElqYgBLUhMDWJKaGMCS1MQAlqQmBrAkNTGAJamJASxJTQxgSWpiAEtSEwNYkpoYwJLUxACWpCYGsCQ1MYAlqYkBLElNDGBJajJqACd5U5IHknwqyXuTnJnk7CR3JXlwuD9rzBokaV6NFsBJNgM/DWyrqm8FTgdeA1wL7K6q84Hdw7IkLZ2xmyA2AE9NsgF4GvAIcAmwa3h+F3DpyDVI0lwaLYCr6m+AdwAPAfuB/1lVfwicW1X7h232A+eMVYMkzbMxmyDOYnK2+1zgm4CnJ3ntDPtfmWRPkj0HDx4cq0xJajNmE8SrgL+uqoNV9VXgNmA78GiSTQDD/YFj7VxVO6tqW1Vt27hx44hlSlKPMQP4IeBlSZ6WJMCFwF7gDmDHsM0O4PYRa5CkubVhrBeuqnuT3ArcBxwCPg7sBJ4B3JLk9UxC+vKxapCkeTZaAANU1duAtx21+stMzoYlaak5Ek6SmhjAktTEAJakJgawJDUxgCWpiQEsSU0MYElqYgBLUhMDWJKaGMCS1MQAlqQmBrAkNTGAJamJASxJTQxgSWpiAEtSEwNYkpoYwJLUxACWpCYGsCQ1MYAlqYkBLElNDGBJamIAS1ITA1iSmhjAktTEAJakJgawJDUxgLW0Nm/ZSpKZbpu3bO0uWwtkQ3cBUpdH9j3MFdffM9M+N1+1faRqtIw8A5akJgawJDUxgCWpiQEsSU0MYElqYgBLUhMDWJKaGMCS1MQA1sKYdWSb1M2RcFoYs45sc1SbunkGLElNDGBJamIAS1ITA1iSmhjAktTEAJakJgawJDUxgCWpiQEsSU0MYElqYgBLUhMDWKdk1olvvJy79EROxqNT4sQ30pPnGbAkNTGAJamJASxJTQxgSWpiAEtSk1EDOMnfSXJrks8k2Zvku5OcneSuJA8O92eNWYMkzauxz4B/Gbizqr4F+HZgL3AtsLuqzgd2D8uStHRGC+AkzwK+B3g3QFV9par+B3AJsGvYbBdw6Vg1SNI8G/MM+HnAQeA/Jvl4khuSPB04t6r2Awz35xxr5yRXJtmTZM/BgwdHLFOSeowZwBuA7wDeVVUvAf43MzQ3VNXOqtpWVds2btw4Vo2S1GbMAN4H7Kuqe4flW5kE8qNJNgEM9wdGrEGS5tZoAVxV/x14OMk3D6suBD4N3AHsGNbtAG4fqwZJmmdjT8bzU8BNSc4APgv8Eyahf0uS1wMPAZePXIMkzaVRA7iqPgFsO8ZTF475vpK0HjgSTpKaGMCS1MQAlqQmBrAkNTGAJamJASxJTQxgSWpiAEtSEwNYkpoYwJLUxACWZnHaBpJMfdu8ZWt3xZpjY0/GIy2Ww4e44vp7pt785qu2j1iM1jvPgCWpiQEsSU0MYElqYgBLUhMDWJKaGMCS1MQAlqQmBrAkNTGAJamJASxJTQxgSWpiAEtSEwNYc2vzlq0zzTwmrTfOhqa59ci+h515TAvNM2BJajJVACe5YJp1kqTpTXsG/KtTrpMkTemEbcBJvhvYDmxM8uYVTz0LOH3MwiRp0Z3sj3BnAM8YtnvmivVfBC4bqyhJWgYnDOCq+lPgT5PcWFWfX6OaJGkpTNsN7SlJdgLnrdynqr53jKIkaRlMG8DvA/4DcAPwtfHKkaTlMW0AH6qqd41aibSITtvgKD0d17QB/LtJ/jnwfuDLR1ZW1d+OUpW0KA4fmmk0Hziib5lMG8A7hvu3rFhXwPNWtxxJWh5TBXBVPXfsQiRp2UwVwEl+4ljrq+o/rW45krQ8pm2C+M4Vj88ELgTuAwxgSTpF0zZB/NTK5STPBt4zSkWStCROdTrK/wOcv5qFSNKymbYN+HeZ9HqAySQ8LwRuGasoSVoG07YBv2PF40PA56tq3wj1SNLSmKoJYpiU5zNMZkQ7C/jKmEVpAQ0jwrzGm/S4aZsg/hHwduBPgAC/muQtVXXriLVpkTgiTHqCaZsgfh74zqo6AJBkI/BHgAEsSado2l4Qpx0J38EXZthXknQM054B35nkD4D3DstXAL8/TkmStBxOdk24FwDnVtVbkvxD4OVM2oA/DNy0BvVJ0sI6WTPCO4EvAVTVbVX15qp6E5Oz33eOW5okLbaTBfB5VfXJo1dW1R4mlyeSJJ2ikwXwmSd47qmrWYgkLZuTBfBHk/zk0SuTvB742DglSdJyOFkviGuA9yf5MR4P3G3AGcCPjFiXJC28EwZwVT0KbE/ySuBbh9W/V1V/PHplkrTgpp0P+G7g7pFrkaSlMvpotiSnJ/l4kg8My2cnuSvJg8P9WWPXIEnzaC2GE78R2Lti+Vpgd1WdD+weliVp6YwawEmeA/wQcMOK1ZcAu4bHu4BLx6xBkubV2GfA7wT+JXB4xbpzq2o/wHB/zrF2THJlkj1J9hw8eHDkMiVp7Y0WwEl+GDhQVafUX7iqdlbVtqratnHjxlWuTpL6TTsb2qm4AHh1kh9kMqLuWUn+M/Bokk1VtT/JJuDACV9FkhbUaGfAVfWzVfWcqjoPeA3wx1X1WuAOYMew2Q7g9rFqkKR51jGp+nXARUkeBC4aliVp6YzZBPH/VdWfMLmeHFX1BeDCtXhfSZpnXlZIkpoYwJLUxACWpCYGsCQ1MYAlqYkBLElNDGBJamIAS1ITA1iSmhjAktTEAJakJgawJDUxgCWpiQEsSU0MYElqYgBLUhMDWJKaGMCS1MQAlqQmBrAkNTGAJamJASxJTQxgSWpiAEtSEwNYkpoYwJLUxACWpCYGsCQ1MYAlqYkBLElNDGBJamIAS1ITA1iSmhjAktTEAJakJgawJDUxgCWpiQEsSU0MYElqYgBLUhMDWJKaGMCS1MQAlqQmBrAkNTGApfXutA0kmem2ecvW7qoFbOguQNKTdPgQV1x/z0y73HzV9pGK0Sw8A5akJgawJDUxgCWpiQEsSU0MYElqYgBLUhMDWJKaGMCS1MQAlqQmBrAkNTGAJanJaAGcZEuSu5PsTfJAkjcO689OcleSB4f7s8aqQdPZvGXrzJO5SHryxpyM5xDwM1V1X5JnAh9LchfwOmB3VV2X5FrgWuBfjViHTuKRfQ87mYvUYLQz4KraX1X3DY+/BOwFNgOXALuGzXYBl45VgyTNszVpA05yHvAS4F7g3KraD5OQBs5Zixokad6MHsBJngH8NnBNVX1xhv2uTLInyZ6DBw+OV6AkNRk1gJN8A5PwvamqbhtWP5pk0/D8JuDAsfatqp1Vta2qtm3cuHHMMiWpxZi9IAK8G9hbVb+04qk7gB3D4x3A7WPVIEnzbMxeEBcAPw7cn+QTw7qfA64DbknyeuAh4PIRa5CkuTVaAFfVnwPH6zB64VjvK0nrhSPhJKmJASxJTQxgSWpiAEtSEwNYkpoYwJLUxACWpCYGsCQ1MYAlqYkBLElNDGBJamIAS1ITA1iSmhjAktTEAJaW0WkbSDL1bfOWrd0VL6QxJ2SXNK8OH+KK6++ZevObr9o+YjHLyzNgSWpiAEtSEwNYkpoYwJLUxACWpCYGsCQ1MYAlqYkBLElNDGBJamIAS1ITA1iSmhjAktTEAJakJgawJDUxgCWpiQEsSU0MYElqYgBLUhMDWJKaGMCS1MQAlqQmBrAkNTGAF9DmLVtJMvVNUo8N3QVo9T2y72GuuP6eqbe/+artI1Yj6Xg8A5akJgawJDUxgCWpiQEsSU0M4Dk3a48GezVI64e9IObcrD0awF4N0nrhGbAkNTGAJamJASxJTQxgSWpiAEtSEwNY0smdtmHm7pAbzjhzpu03b9nafZRrzm5okk7u8KFT6g7ppFAn5hmwJDUxgCWpiQEsSU0MYElqYgBLUpOWAE5ycZK/TPJXSa4d631mnUlsLbrBeL026Thm7Oo2aze3eewat+bd0JKcDvx74CJgH/DRJHdU1adX+73m8dpo81iTNBdm7Oo2aze3U9ln7O9fxxnwS4G/qqrPVtVXgN8CLmmoQ5JaparW9g2Ty4CLq+qfDss/DnxXVV191HZXAlcOi98M/OXIpX0j8NjI79FhUY8LPLb1alGPbeVxPVZVF59sh46RcMdq2HzCT4Gq2gnsHL+ciSR7qmrbWr3fWlnU4wKPbb1a1GM7lePqaILYB2xZsfwc4JGGOiSpVUcAfxQ4P8lzk5wBvAa4o6EOSWq15k0QVXUoydXAHwCnA79RVQ+sdR3HsGbNHWtsUY8LPLb1alGPbebjWvM/wkmSJhwJJ0lNDGBJamIAD5L86yR/k+QTw+0Hu2t6stZqyHeHJJ9Lcv/wWe3prufJSPIbSQ4k+dSKdWcnuSvJg8P9WZ01norjHNdCfM+SbElyd5K9SR5I8sZh/UyfmwH89f5dVb14uP1+dzFPxooh3z8AvAj40SQv6q1q1b1y+KzWe5/SG4GjO+1fC+yuqvOB3cPyenMjTzwuWIzv2SHgZ6rqhcDLgDcM36+ZPjcDeHE55HudqKoPAn971OpLgF3D413ApWtZ02o4znEthKraX1X3DY+/BOwFNjPj52YAf72rk3xy+NVp3f3Kd5TNwMMrlvcN6xZFAX+Y5GPDsPVFc25V7YfJlx04p7me1bRI3zOSnAe8BLiXGT+3pQrgJH+U5FPHuF0CvAt4PvBiYD/wbztrXQVTDflexy6oqu9g0sTyhiTf012QprJQ37MkzwB+G7imqr446/5LdVXkqnrVNNsl+XXgAyOXM7aFHvJdVY8M9weSvJ9Jk8sHe6taVY8m2VRV+5NsAg50F7QaqurRI4/X+/csyTcwCd+bquq2YfVMn9tSnQGfyPCPdcSPAJ863rbrxMIO+U7y9CTPPPIY+D7W/+d1tDuAHcPjHcDtjbWsmkX5nmVytYR3A3ur6pdWPDXT5+ZIuEGS9zD5taiAzwFXHWnLWa+GLj7v5PEh37/YW9HqSPI84P3D4gbgN9fzsSV5L/AKJtMZPgq8Dfgd4BZgK/AQcHlVras/aB3nuF7BAnzPkrwc+DPgfuDwsPrnmLQDT/25GcCS1MQmCElqYgBLUhMDWJKaGMCS1MQAlqQmBrAkNTGANXeSvPrJTJ+Z5JokT1vNmsaU5NIFnKlOU7AfsBZOks8B26rqse5appHkRuADVXVrdy1aW54Ba00lOS/JZ5LcMEyEdFOSVyX50DCJ9UuTvC7Jrw3b35jkV5Lck+SzSS4b1r8iyQdWvO6vDfv9NPBNwN1J7h6e+74kH05yX5L3DROokOS6JJ8eZuZ6xwlqvnyo9S+SfHBY97oktye5c5j0/m0rtn9tkv86TDh+/TA3M0n+V5JfHF7nI0nOTbIdeDXw9mH756/2v7nmlwGsDi8Afhn4NuBbgH8MvBz4F0yGcx5t0/D8DwPXneiFq+pXmEw69MqqemWSbwTeCrxqmD1tD/DmJGczmYvg71fVtwH/5gQv+wvA91fVtzMJyyNeCvwYk6G1lyfZluSFwBVMZmt7MfC1YRuApwMfGV7ng8BPVtU9TOYPeMswQfl/O9HxabEs1Wxomht/XVX3AyR5gMkVBCrJ/cB5x9j+d6rqMPDpJOfO+F4vY3JFkA9N5k/hDODDwBeB/wvckOT3OPGsXB8CbkxyC3DbivV3VdUXhuO4jckPiUPAPwA+OrzfU3l8RqyvrHifjwEXzXgsWjAGsDp8ecXjwyuWD3Ps/5Mrtz8yz/Ehvv43uDOP815hEpQ/+oQnkpcCFzKZKe5q4HuP9QJV9c+SfBfwQ8Ankrz4yFNHbzq8366q+tljvNRX6/E/unwNv39LzyYIrVefB16U5ClJns0kSI/4EvDM4fFHgAuSvAAgydOS/L2hHfjZwzXJrmHSjHBMSZ5fVfdW1S8Aj/H4PMsXZXIRxqcyufTMh5hcB+yyJOcM+56d5O+e5FhW1qsl4k9grUtV9fDQJPBJ4EHg4yue3gn8lyT7h3bg1wHvTfKU4fm3Mgm925OcyeSs9U0neLu3Jzl/2G438BdMAvvPgfcwadP+zaraA5DkrUwul3Qa8FXgDUx+YBzPbwG/PvwB8TLbgZeH3dCkUzCE+raqurq7Fq1fNkFIUhPPgKVBkp8HLj9q9fvW89U2NN8MYElqYhOEJDUxgCWpiQEsSU0MYElq8v8A/G6RovoiwokAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(data_ex2['minutes_spent'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude minutes spent which less than 0 (exclude 7 rows out of 600 or around 1% of data)\n",
    "sum(data_ex2['minutes_spent'] < 0)\n",
    "\n",
    "data_ex2_clean_min = data_ex2[data_ex2['minutes_spent'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.007968754671815e-10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_spent_old = np.array(data_ex2_clean_min[data_ex2_clean_min['website_design'] == 0]['minutes_spent'])\n",
    "time_spent_new = np.array(data_ex2_clean_min[data_ex2_clean_min['website_design'] == 1]['minutes_spent'])\n",
    "zstat, p_value = ttest_ind(time_spent_old\n",
    "                           ,time_spent_new\n",
    "                           ,alternative = 'two-sided')\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. There is concern that there may have been a programming error regarding the random assignment of consumers. Specifically, it may be that the selection of the 10% of customer traffic that was directed to the newly designed website was not random. Does the data suggest that this concern is legitimate? Even if it was not random, does the data suggest that our conclusions about the new website design observed in **part a** should change? Be specific about your approach (set you alpha-level at 0.05). State the null/alternative hypothesis and your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "I focused on member because it is the only thing the company knows before the selection. I used chi-squared test of independent to test whether website design and member status related.\n",
    "\n",
    "*Hypothesis*<br>\n",
    "$H_0$: website design and member status are independent.<br>\n",
    "$H_1$: website design and member status are not independent.\n",
    "\n",
    "P-value that I got from chi-squared is nearly 0.00. Thus, I can reject $H_0$ and conclude that website design and member status are not independent. In other words, the selection of customers directed to new website design is not random.\n",
    "\n",
    "I then perform a proportion test for proportion of sales in each member type. I found that p-value of both member type are significantly large amount. This leads to change in result in part a. I then tested wheter the membership impact the sales rate. I got p-value nearly 0.000 and can conclude that the visitors who are members more likely to make purchase regardless the website design.\n",
    "\n",
    "To conclude, the type of member ship impact the sales rate. The company tends to choose member to land on the new website. Thus, the company cannot conclude that new website design lead to higher rate of sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "member = np.array(data_ex2[data_ex2['member']==1]['website_design'].value_counts())\n",
    "non_member = np.array(data_ex2[data_ex2['member']==0]['website_design'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3140740608613126e-17"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Test Hypothesis for independence\n",
    "test_stat, p_value, df, data  = chi2_contingency([member,non_member])\n",
    "\n",
    "p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.535649477718982"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test sale proportion for member\n",
    "zstat, p_value = proportions_ztest(count= np.array([data_ex2[(data_ex2['member'] == 1) & (data_ex2['website_design'] == 0)]['sale_1_0'].sum(),data_ex2[(data_ex2['member'] == 1) & (data_ex2['website_design'] == 1)]['sale_1_0'].sum()])\n",
    "                                   ,nobs=np.array([data_ex2[(data_ex2['member'] == 1) & (data_ex2['website_design'] == 0)]['sale_1_0'].count(),data_ex2[(data_ex2['member'] == 1) & (data_ex2['website_design'] == 1)]['sale_1_0'].count()])\n",
    "                                   ,alternative = 'smaller')\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918251644314425"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test sale proportion for non-member\n",
    "zstat, p_value = proportions_ztest(count= np.array([data_ex2[(data_ex2['member'] == 0) & (data_ex2['website_design'] == 0)]['sale_1_0'].sum(),data_ex2[(data_ex2['member'] == 0) & (data_ex2['website_design'] == 1)]['sale_1_0'].sum()])\n",
    "                                   ,nobs=np.array([data_ex2[(data_ex2['member'] == 0) & (data_ex2['website_design'] == 0)]['sale_1_0'].count(),data_ex2[(data_ex2['member'] == 0) & (data_ex2['website_design'] == 1)]['sale_1_0'].count()])\n",
    "                                   ,alternative = 'smaller')\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.931853818047788, 8.117293709207258e-28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test sale proportion by type of member\n",
    "zstat, p_value = proportions_ztest(count= np.array([data_ex2[(data_ex2['member'] == 1)]['sale_1_0'].sum(),data_ex2[(data_ex2['member'] == 0)]['sale_1_0'].sum()])\n",
    "                                   ,nobs=np.array([data_ex2[(data_ex2['member'] == 1)]['sale_1_0'].count(),data_ex2[(data_ex2['member'] == 0)]['sale_1_0'].count()])\n",
    "                                   ,alternative = 'two-sided')\n",
    "\n",
    "zstat, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. The company is worried that the introduction of the new features (more product pictures and zoom feature) is having an impact on customers returning the products they purchased. Statistically examine the impact of the new website design on returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "I use proportion test to test whether the percentage of visitors who returned the products between new and old website desigh is different.\n",
    "\n",
    "*Hypothesis*<br>\n",
    "$H_0$: Proportion of returned products of new website design is not differ from those of old website design.<br>\n",
    "$H_0$: Proportion of returned products of new website design is differ from those of old website design.\n",
    "\n",
    "From the test for all data, z-score is -4.50 and p-value is approximately 0.000. Thus, we can reject $H_0$ and conclude that visitors in new website design are more likely to return products. However, as stated in part c that the selection is not random, I divided the data into two groups, non-member and member, and performed the test again. Surprisingly, the p-value for both group are 0.55 and 0.22. This means that I cannot reject $H_0$. I then test the return proportion to see if there is any different between member and non-member customers. I got z-score 7.33 and p-value approximately 0.000. I can conclude that customers who are member are more likely to return the products, regardless the website design.\n",
    "\n",
    "In conclusion, the company directed more member to new website design than non-member and the type of membership impact the return rate. Because of these effects, the company cannot prove that the website design impact the products return rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.501296433526966, 6.75402320085793e-06)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test return proportion for overall\n",
    "zstat, p_value = proportions_ztest(count= np.array([data_ex2[(data_ex2['website_design'] == 0)]['return_1_0'].sum(),data_ex2[(data_ex2['member'] == 1)]['return_1_0'].sum()])\n",
    "                                   ,nobs=np.array([data_ex2[(data_ex2['website_design'] == 0)]['return_1_0'].count(),data_ex2[(data_ex2['member'] == 1)]['return_1_0'].count()])\n",
    "                                   ,alternative = 'two-sided')\n",
    "\n",
    "zstat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6025109040558653, 0.5468341071264461)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test return proportion for non-member\n",
    "zstat, p_value = proportions_ztest(count= np.array([data_ex2[(data_ex2['member'] == 0) & (data_ex2['website_design'] == 0)]['return_1_0'].sum(),data_ex2[(data_ex2['member'] == 0) & (data_ex2['website_design'] == 1)]['return_1_0'].sum()])\n",
    "                                   ,nobs=np.array([data_ex2[(data_ex2['member'] == 0) & (data_ex2['website_design'] == 0)]['return_1_0'].count(),data_ex2[(data_ex2['member'] == 0) & (data_ex2['website_design'] == 1)]['return_1_0'].count()])\n",
    "                                   ,alternative = 'two-sided')\n",
    "\n",
    "zstat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2314090654388625, 0.21816990810018433)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test return proportion for member\n",
    "zstat, p_value = proportions_ztest(count= np.array([data_ex2[(data_ex2['member'] == 1) & (data_ex2['website_design'] == 0)]['return_1_0'].sum(),data_ex2[(data_ex2['member'] == 1) & (data_ex2['website_design'] == 1)]['return_1_0'].sum()])\n",
    "                                   ,nobs=np.array([data_ex2[(data_ex2['member'] == 1) & (data_ex2['website_design'] == 0)]['return_1_0'].count(),data_ex2[(data_ex2['member'] == 1) & (data_ex2['website_design'] == 1)]['return_1_0'].count()])\n",
    "                                   ,alternative = 'two-sided')\n",
    "\n",
    "zstat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.334150265369788, 2.2313263492972675e-13)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test return proportion between each member type\n",
    "zstat, p_value = proportions_ztest(count= np.array([data_ex2[(data_ex2['member'] == 1)]['return_1_0'].sum(),data_ex2[(data_ex2['member'] == 0)]['return_1_0'].sum()])\n",
    "                                   ,nobs=np.array([data_ex2[(data_ex2['member'] == 1)]['return_1_0'].count(),data_ex2[(data_ex2['member'] == 0)]['return_1_0'].count()])\n",
    "                                   ,alternative = 'two-sided')\n",
    "\n",
    "zstat, p_value"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58e9d0bbcbc5aa8fd8ef455c7e360d8e49433060d10134250ffe571fc3da7e24"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
